{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e2dc07",
   "metadata": {},
   "source": [
    "# 1. Ablation testing using pretrained huggingface t5-small\n",
    "\n",
    "\n",
    "Source github: https://github.com/Shivanandroy/T5-Finetuning-PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "430b7c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\cedri\\miniconda3\\lib\\site-packages (0.1.96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\cedri\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\cedri\\miniconda3\\lib\\site-packages (4.16.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (1.21.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (2022.1.18)\n",
      "Requirement already satisfied: requests in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: filelock in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from transformers) (0.11.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from sacremoses->transformers) (7.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\cedri\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\cedri\\miniconda3\\lib\\site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from torch) (4.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\cedri\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rich[jupyter] in c:\\users\\cedri\\miniconda3\\lib\\site-packages (11.2.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from rich[jupyter]) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from rich[jupyter]) (2.10.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from rich[jupyter]) (0.4.4)\n",
      "Requirement already satisfied: ipywidgets<8.0.0,>=7.5.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from rich[jupyter]) (7.6.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.0.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.6.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (7.30.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (7.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (60.9.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.0.23)\n",
      "Requirement already satisfied: backcall in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.18.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.2.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.9.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.18.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.5.4)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (22.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.3)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (228)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.3.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.1.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.12.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.0.3)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.12.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.15.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.1.6)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.14.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.0.1)\n",
      "Requirement already satisfied: bleach in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.9)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.1.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.20)\n",
      "Requirement already satisfied: packaging in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (20.9)\n",
      "Requirement already satisfied: webencodings in c:\\users\\cedri\\miniconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\cedri\\appdata\\roaming\\python\\python39\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\cedri\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# install libraries\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install rich[jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceacb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import os\n",
    "\n",
    "# Importing the T5 modules from huggingface/transformers\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoModel\n",
    "\n",
    "# rich: for a better display on terminal\n",
    "from rich.table import Column, Table\n",
    "from rich import box\n",
    "from rich.console import Console"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd12e69",
   "metadata": {},
   "source": [
    "#### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ed6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605837fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29574</th>\n",
       "      <td>India ought to be one of our closest partners:...</td>\n",
       "      <td>India \"ought to be\" one of US' closest partner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68868</th>\n",
       "      <td>PM Modi releases postage stamp on Lord Ram in ...</td>\n",
       "      <td>Prime Minister Narendra Modi has released a po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76670</th>\n",
       "      <td>Mumbai to get new cruise terminal featuring ho...</td>\n",
       "      <td>The Mumbai Port Trust (MbPT) has awarded contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25305</th>\n",
       "      <td>YouTube now allows users to search videos usin...</td>\n",
       "      <td>Google-owned video sharing platform YouTube no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70388</th>\n",
       "      <td>Taapsee Pannu responds to user trolling her bi...</td>\n",
       "      <td>Taapsee Pannu responded to a Twitter user who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27540</th>\n",
       "      <td>ICC to give strict ball tampering bans post Au...</td>\n",
       "      <td>ICC has decided to hand stricter bans for ball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25404</th>\n",
       "      <td>Dhoni not the same person he was, age catching...</td>\n",
       "      <td>Following India's series defeat against Englan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94975</th>\n",
       "      <td>New York's Eleven Madison Park named world's b...</td>\n",
       "      <td>Eleven Madison Park in New York has topped the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51707</th>\n",
       "      <td>Woman player awarded 'Spirit of Cricket' for c...</td>\n",
       "      <td>England's woman cricketer Anya Shrubsole won t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59420</th>\n",
       "      <td>Sunny Leone says Jet Airways delays ruined 'we...</td>\n",
       "      <td>Actress Sunny Leone and her husband Daniel Web...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "29574  India ought to be one of our closest partners:...   \n",
       "68868  PM Modi releases postage stamp on Lord Ram in ...   \n",
       "76670  Mumbai to get new cruise terminal featuring ho...   \n",
       "25305  YouTube now allows users to search videos usin...   \n",
       "70388  Taapsee Pannu responds to user trolling her bi...   \n",
       "27540  ICC to give strict ball tampering bans post Au...   \n",
       "25404  Dhoni not the same person he was, age catching...   \n",
       "94975  New York's Eleven Madison Park named world's b...   \n",
       "51707  Woman player awarded 'Spirit of Cricket' for c...   \n",
       "59420  Sunny Leone says Jet Airways delays ruined 'we...   \n",
       "\n",
       "                                                    text  \n",
       "29574  India \"ought to be\" one of US' closest partner...  \n",
       "68868  Prime Minister Narendra Modi has released a po...  \n",
       "76670  The Mumbai Port Trust (MbPT) has awarded contr...  \n",
       "25305  Google-owned video sharing platform YouTube no...  \n",
       "70388  Taapsee Pannu responded to a Twitter user who ...  \n",
       "27540  ICC has decided to hand stricter bans for ball...  \n",
       "25404  Following India's series defeat against Englan...  \n",
       "94975  Eleven Madison Park in New York has topped the...  \n",
       "51707  England's woman cricketer Anya Shrubsole won t...  \n",
       "59420  Actress Sunny Leone and her husband Daniel Web...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648d8e6f",
   "metadata": {},
   "source": [
    "#### Display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e332fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a rich console logger\n",
    "console = Console(record=True)\n",
    "\n",
    "# to display dataframe in ASCII format\n",
    "def display_df(df):\n",
    "    \"\"\"display dataframe in ASCII format\"\"\"\n",
    "\n",
    "    console = Console()\n",
    "    table = Table(\n",
    "        Column(\"source_text\", justify=\"center\"),\n",
    "        Column(\"target_text\", justify=\"center\"),\n",
    "        title=\"Sample Data\",\n",
    "        pad_edge=False,\n",
    "        box=box.ASCII,\n",
    "    )\n",
    "\n",
    "    for i, row in enumerate(df.values.tolist()):\n",
    "        table.add_row(row[0], row[1])\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "# training logger to log training progress\n",
    "training_logger = Table(\n",
    "    Column(\"Epoch\", justify=\"center\"),\n",
    "    Column(\"Steps\", justify=\"center\"),\n",
    "    Column(\"Loss\", justify=\"center\"),\n",
    "    title=\"Training Status\",\n",
    "    pad_edge=False,\n",
    "    box=box.ASCII,\n",
    ")\n",
    "\n",
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d2eec3",
   "metadata": {},
   "source": [
    "#### Custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e35cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourDataSetClass(Dataset):\n",
    "    \"\"\"\n",
    "    Creating a custom dataset for reading the dataset and\n",
    "    loading it into the dataloader to pass it to the\n",
    "    neural network for finetuning the model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a Dataset class\n",
    "\n",
    "        Args:\n",
    "            dataframe (pandas.DataFrame): Input dataframe\n",
    "            tokenizer (transformers.tokenizer): Transformers tokenizer\n",
    "            source_len (int): Max length of source text\n",
    "            target_len (int): Max length of target text\n",
    "            source_text (str): column name of source text\n",
    "            target_text (str): column name of target text\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = target_len\n",
    "        self.target_text = self.data[target_text]\n",
    "        self.source_text = self.data[source_text]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"returns the length of dataframe\"\"\"\n",
    "\n",
    "        return len(self.target_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"return the input ids, attention masks and target ids\"\"\"\n",
    "\n",
    "        source_text = str(self.source_text[index])\n",
    "        target_text = str(self.target_text[index])\n",
    "\n",
    "        # cleaning data so as to ensure data is in string type\n",
    "        source_text = \" \".join(source_text.split())\n",
    "        target_text = \" \".join(target_text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus(\n",
    "            [source_text],\n",
    "            max_length=self.source_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        target = self.tokenizer.batch_encode_plus(\n",
    "            [target_text],\n",
    "            max_length=self.summ_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        source_mask = source[\"attention_mask\"].squeeze()\n",
    "        target_ids = target[\"input_ids\"].squeeze()\n",
    "        target_mask = target[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\n",
    "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
    "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
    "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
    "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385ab34",
   "metadata": {},
   "source": [
    "#### Train and validate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c493c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to be called for training with the parameters passed from main function\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    for _, data in enumerate(loader, 0):\n",
    "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=ids,\n",
    "            attention_mask=mask,\n",
    "            decoder_input_ids=y_ids,\n",
    "            labels=lm_labels,\n",
    "        )\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if _ % 10 == 0:\n",
    "            training_logger.add_row(str(epoch), str(_), str(loss))\n",
    "            console.print(training_logger)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    \"\"\"\n",
    "    Function to evaluate model for predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            \n",
    "            \n",
    "            generated_ids = model.generate(\n",
    "              input_ids = ids,\n",
    "              attention_mask = mask, \n",
    "              max_length=150, \n",
    "              num_beams=2,\n",
    "              repetition_penalty=2.5, \n",
    "              length_penalty=1.0, \n",
    "              early_stopping=True\n",
    "              )\n",
    "            \n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%10==0:\n",
    "                \n",
    "                console.print(f'Completed {_}')\n",
    "                \n",
    "                \n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f5278",
   "metadata": {},
   "source": [
    "#### T5 Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88ddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T5Trainer(\n",
    "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    T5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text, target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\n",
    "    train_size = 0.8\n",
    "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
    "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "    val_set = YourDataSetClass(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "    # evaluating test dataset\n",
    "    console.log(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af19832",
   "metadata": {},
   "source": [
    "#### Model paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aad7410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# let's define model parameters specific to T5\n",
    "model_params = {\n",
    "    \"MODEL\": \"t5-small\",  # model_type: t5-base/t5-large\n",
    "    \"TRAIN_BATCH_SIZE\": 4,  # training batch size\n",
    "    \"VALID_BATCH_SIZE\": 4,  # validation batch size\n",
    "    \"TRAIN_EPOCHS\": 3,  # number of training epochs\n",
    "    \"VAL_EPOCHS\": 1,  # number of validation epochs\n",
    "    \"LEARNING_RATE\": 1e-4,  # learning rate\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 50,  # max length of target text\n",
    "    \"SEED\": 42,  # set seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e1458d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get a news summary dataset\n",
    "# dataframe has 2 columns: \n",
    "#   - text: long article content\n",
    "#   - headlines: one line summary of news\n",
    "path = \"https://raw.githubusercontent.com/Shivanandroy/T5-Finetuning-PyTorch/main/data/news_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# T5 accepts prefix of the task to be performed:\n",
    "# Since we are summarizing, let's add summarize to source text as a prefix\n",
    "df[\"text\"] = \"summarize: \" + df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972ed41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:41:01] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-small<span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#16\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:41:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-small\u001b[33m...\u001b[0m           \u001b]8;id=760384;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=770144;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                       \u001b[2m                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:41:14] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#27\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">27</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:41:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                \u001b]8;id=403549;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=415563;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#27\u001b\\\u001b[2m27\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                       \u001b[2m                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Sample Data                                         </span>\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                source_text                  </span>|<span style=\"font-weight: bold\">                 target_text                 </span>|\n",
       "|---------------------------------------------+---------------------------------------------|\n",
       "|summarize: Saurav Kant, an alumnus of upGrad | upGrad learner switches to career in ML &amp; Al|\n",
       "|and IIIT-B's PG Program in Machine learning  |             with 90% salary hike            |\n",
       "|   and Artificial Intelligence, was a Sr     |                                             |\n",
       "| Systems Engineer at Infosys with almost 5   |                                             |\n",
       "| years of work experience. The program and   |                                             |\n",
       "| upGrad's 360-degree career support helped   |                                             |\n",
       "| him transition to a Data Scientist at Tech  |                                             |\n",
       "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
       "| Online Power Learning has powered 3 lakh+   |                                             |\n",
       "|                  careers.                   |                                             |\n",
       "|  summarize: Kunal Shah's credit card bill   | Delhi techie wins free food from Swiggy for |\n",
       "|payment platform, CRED, gave users a chance  |               one year on CRED              |\n",
       "| to win free food from Swiggy for one year.  |                                             |\n",
       "|Pranav Kaushik, a Delhi techie, bagged this  |                                             |\n",
       "|reward after spending 2000 CRED coins. Users |                                             |\n",
       "| get one CRED coin per rupee of bill paid,   |                                             |\n",
       "|  which can be used to avail rewards from    |                                             |\n",
       "|  brands like Ixigo, BookMyShow, UberEats,   |                                             |\n",
       "|             Cult.Fit and more.              |                                             |\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         Sample Data                                         \u001b[0m\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                source_text                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                target_text                 \u001b[0m|\n",
       "|---------------------------------------------+---------------------------------------------|\n",
       "|summarize: Saurav Kant, an alumnus of upGrad | upGrad learner switches to career in ML & Al|\n",
       "|and IIIT-B's PG Program in Machine learning  |             with 90% salary hike            |\n",
       "|   and Artificial Intelligence, was a Sr     |                                             |\n",
       "| Systems Engineer at Infosys with almost 5   |                                             |\n",
       "| years of work experience. The program and   |                                             |\n",
       "| upGrad's 360-degree career support helped   |                                             |\n",
       "| him transition to a Data Scientist at Tech  |                                             |\n",
       "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
       "| Online Power Learning has powered 3 lakh+   |                                             |\n",
       "|                  careers.                   |                                             |\n",
       "|  summarize: Kunal Shah's credit card bill   | Delhi techie wins free food from Swiggy for |\n",
       "|payment platform, CRED, gave users a chance  |               one year on CRED              |\n",
       "| to win free food from Swiggy for one year.  |                                             |\n",
       "|Pranav Kaushik, a Delhi techie, bagged this  |                                             |\n",
       "|reward after spending 2000 CRED coins. Users |                                             |\n",
       "| get one CRED coin per rupee of bill paid,   |                                             |\n",
       "|  which can be used to avail rewards from    |                                             |\n",
       "|  brands like Ixigo, BookMyShow, UberEats,   |                                             |\n",
       "|             Cult.Fit and more.              |                                             |\n",
       "+-------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>            <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#85\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">85</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m            \u001b]8;id=184880;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33841;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#85\u001b\\\u001b[2m85\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                       \u001b[2m                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:42:08] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                      <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#90\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:42:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                      \u001b]8;id=848702;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=83950;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                       \u001b[2m                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:42:09] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>             <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#97\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">97</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:42:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m             \u001b]8;id=190997;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=443996;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#97\u001b\\\u001b[2m97\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                       \u001b[2m                                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:42:35] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>               <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/689430518.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#105\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:42:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m               \u001b]8;id=103765;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/689430518.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=6068;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\689430518.py#105\u001b\\\u001b[2m105\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                      \u001b[2m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs\\model_files\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs\\model_files\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs\\logs.txt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs\\logs.txt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T5Trainer(dataframe=df[:500], source_text=\"text\", target_text=\"headlines\", model_params=model_params, output_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790239ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7e14e",
   "metadata": {},
   "source": [
    "### Check validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b39ddc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunrise Lee gave doctor lap dance to persuade ...</td>\n",
       "      <td>Pharma exec gave doctor a lap dance to sell me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PM Modi says opposition talks only about Modi ...</td>\n",
       "      <td>I think the opposition even dreams about me: P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Indian Space Research Organisation unveils hum...</td>\n",
       "      <td>ISRO unveils Bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rahul Gandhi replies to Goa CM's letter accusi...</td>\n",
       "      <td>CM Parrikar under pressure from PM after our G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>eUFS will let smartphones store 260 videos sho...</td>\n",
       "      <td>Samsung builds world's first 1TB storage chip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>woman got leg stuck inside toilet hole after f...</td>\n",
       "      <td>Railway police rescues woman with leg stuck in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>the move is a \"response to the illegal migrati...</td>\n",
       "      <td>US begins sending back asylum seekers to Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Yashwant Sinha demands probe into loans worth ...</td>\n",
       "      <td>Yashwant Sinha demands probe into alleged fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>text</td>\n",
       "      <td>headlines</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     Generated Text  \\\n",
       "0           0  Kunal Shah's credit card bill payment platform...   \n",
       "1           1  Sunrise Lee gave doctor lap dance to persuade ...   \n",
       "2           2  PM Modi says opposition talks only about Modi ...   \n",
       "3           3  Indian Space Research Organisation unveils hum...   \n",
       "4           4  Rahul Gandhi replies to Goa CM's letter accusi...   \n",
       "5           5  eUFS will let smartphones store 260 videos sho...   \n",
       "6           6  woman got leg stuck inside toilet hole after f...   \n",
       "7           7  the move is a \"response to the illegal migrati...   \n",
       "8           8  Yashwant Sinha demands probe into loans worth ...   \n",
       "9           9                                               text   \n",
       "\n",
       "                                         Actual Text  \n",
       "0  Delhi techie wins free food from Swiggy for on...  \n",
       "1  Pharma exec gave doctor a lap dance to sell me...  \n",
       "2  I think the opposition even dreams about me: P...  \n",
       "3  ISRO unveils Bengaluru centre for manned space...  \n",
       "4  CM Parrikar under pressure from PM after our G...  \n",
       "5  Samsung builds world's first 1TB storage chip ...  \n",
       "6  Railway police rescues woman with leg stuck in...  \n",
       "7    US begins sending back asylum seekers to Mexico  \n",
       "8  Yashwant Sinha demands probe into alleged fund...  \n",
       "9                                          headlines  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_val = pd.read_csv(\"outputs/predictions.csv\")\n",
    "\n",
    "df_val[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c45bbb",
   "metadata": {},
   "source": [
    "## Prune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718dc10",
   "metadata": {},
   "source": [
    "Load a pretrained t5-small model from transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7f2ab2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0686527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5Model.from_pretrained(model_params[\"MODEL\"])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29cd66",
   "metadata": {},
   "source": [
    "Check the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2c859906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "bd8a9d41",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5Stack' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_34632/1744380713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mheads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cedri\\miniconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mprune_heads\u001b[1;34m(self, heads_to_prune)\u001b[0m\n\u001b[0;32m    959\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruned_heads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munion_heads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Unfortunately we have to store it as list for JSON\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prune_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheads_to_prune\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient_checkpointing_enable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cedri\\miniconda3\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py\u001b[0m in \u001b[0;36m_prune_heads\u001b[1;34m(self, heads_to_prune)\u001b[0m\n\u001b[0;32m   1317\u001b[0m         \"\"\"\n\u001b[0;32m   1318\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheads\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mheads_to_prune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1319\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune_heads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0madd_start_docstrings_to_model_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT5_INPUTS_DOCSTRING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cedri\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'T5Stack' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "# Heads to remove as a dict. The key represents the layer number and values is an array of the heads to remove\n",
    "# Here 0: [0, 1] means remove from layer 0, head 0 and 1\n",
    "heads = { 0: [0, 1], 1: [0, 1] }\n",
    "\n",
    "model = model.prune_heads(heads)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9733aad",
   "metadata": {},
   "source": [
    "#### New trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3015b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T5Trainer(\n",
    "    dataframe, source_text, target_text, model_params, output_dir=\"./outputs/\"\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    T5 trainer\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "    # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary.\n",
    "    # Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
    "    model = model.to(device)\n",
    "    heads = { 1: [0, 1], 2: [0, 2] }\n",
    "\n",
    "    model.prune_heads = heads\n",
    "\n",
    "    # logging\n",
    "    console.log(f\"[Data]: Reading data...\\n\")\n",
    "\n",
    "    # Importing the raw dataset\n",
    "    dataframe = dataframe[[source_text, target_text]]\n",
    "    display_df(dataframe.head(2))\n",
    "\n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest for validation.\n",
    "    train_size = 0.8\n",
    "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
    "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    console.print(f\"FULL Dataset: {dataframe.shape}\")\n",
    "    console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
    "    console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = YourDataSetClass(\n",
    "        train_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "    val_set = YourDataSetClass(\n",
    "        val_dataset,\n",
    "        tokenizer,\n",
    "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
    "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
    "        source_text,\n",
    "        target_text,\n",
    "    )\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    val_params = {\n",
    "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 0,\n",
    "    }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session.\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=model_params[\"LEARNING_RATE\"]\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    console.log(f\"[Initiating Fine Tuning]...\\n\")\n",
    "\n",
    "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "\n",
    "    console.log(f\"[Saving Model]...\\n\")\n",
    "    # Saving the model after training\n",
    "    path = os.path.join(output_dir, \"model_files\")\n",
    "    model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)\n",
    "\n",
    "    # evaluating test dataset\n",
    "    console.log(f\"[Initiating Validation]...\\n\")\n",
    "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
    "        final_df.to_csv(os.path.join(output_dir, \"ablation_predictions.csv\"))\n",
    "\n",
    "    console.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
    "\n",
    "    console.log(f\"[Validation Completed.]\\n\")\n",
    "    console.print(\n",
    "        f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\"\n",
    "    )\n",
    "    console.print(\n",
    "        f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\"\n",
    "    )\n",
    "    console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97242801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:42:45] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-small<span style=\"color: #808000; text-decoration-color: #808000\">...</span>          <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#16\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:42:45]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-small\u001b[33m...\u001b[0m          \u001b]8;id=35809;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=99484;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#16\u001b\\\u001b[2m16\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                      \u001b[2m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:42:57] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>               <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#30\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">30</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:42:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m               \u001b]8;id=239486;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=819082;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#30\u001b\\\u001b[2m30\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                      \u001b[2m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         Sample Data                                         </span>\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">                source_text                  </span>|<span style=\"font-weight: bold\">                 target_text                 </span>|\n",
       "|---------------------------------------------+---------------------------------------------|\n",
       "|summarize: Saurav Kant, an alumnus of upGrad | upGrad learner switches to career in ML &amp; Al|\n",
       "|and IIIT-B's PG Program in Machine learning  |             with 90% salary hike            |\n",
       "|   and Artificial Intelligence, was a Sr     |                                             |\n",
       "| Systems Engineer at Infosys with almost 5   |                                             |\n",
       "| years of work experience. The program and   |                                             |\n",
       "| upGrad's 360-degree career support helped   |                                             |\n",
       "| him transition to a Data Scientist at Tech  |                                             |\n",
       "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
       "| Online Power Learning has powered 3 lakh+   |                                             |\n",
       "|                  careers.                   |                                             |\n",
       "|  summarize: Kunal Shah's credit card bill   | Delhi techie wins free food from Swiggy for |\n",
       "|payment platform, CRED, gave users a chance  |               one year on CRED              |\n",
       "| to win free food from Swiggy for one year.  |                                             |\n",
       "|Pranav Kaushik, a Delhi techie, bagged this  |                                             |\n",
       "|reward after spending 2000 CRED coins. Users |                                             |\n",
       "| get one CRED coin per rupee of bill paid,   |                                             |\n",
       "|  which can be used to avail rewards from    |                                             |\n",
       "|  brands like Ixigo, BookMyShow, UberEats,   |                                             |\n",
       "|             Cult.Fit and more.              |                                             |\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         Sample Data                                         \u001b[0m\n",
       "+-------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m                source_text                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                target_text                 \u001b[0m|\n",
       "|---------------------------------------------+---------------------------------------------|\n",
       "|summarize: Saurav Kant, an alumnus of upGrad | upGrad learner switches to career in ML & Al|\n",
       "|and IIIT-B's PG Program in Machine learning  |             with 90% salary hike            |\n",
       "|   and Artificial Intelligence, was a Sr     |                                             |\n",
       "| Systems Engineer at Infosys with almost 5   |                                             |\n",
       "| years of work experience. The program and   |                                             |\n",
       "| upGrad's 360-degree career support helped   |                                             |\n",
       "| him transition to a Data Scientist at Tech  |                                             |\n",
       "|  Mahindra with 90% salary hike. upGrad's    |                                             |\n",
       "| Online Power Learning has powered 3 lakh+   |                                             |\n",
       "|                  careers.                   |                                             |\n",
       "|  summarize: Kunal Shah's credit card bill   | Delhi techie wins free food from Swiggy for |\n",
       "|payment platform, CRED, gave users a chance  |               one year on CRED              |\n",
       "| to win free food from Swiggy for one year.  |                                             |\n",
       "|Pranav Kaushik, a Delhi techie, bagged this  |                                             |\n",
       "|reward after spending 2000 CRED coins. Users |                                             |\n",
       "| get one CRED coin per rupee of bill paid,   |                                             |\n",
       "|  which can be used to avail rewards from    |                                             |\n",
       "|  brands like Ixigo, BookMyShow, UberEats,   |                                             |\n",
       "|             Cult.Fit and more.              |                                             |\n",
       "+-------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#88\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m           \u001b]8;id=168255;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=533776;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#88\u001b\\\u001b[2m88\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                      \u001b[2m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Training Status                               </span>\n",
       "+---------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                            </span>|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=&lt;NllLossBackward0&gt;)|\n",
       "+---------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Training Status                               \u001b[0m\n",
       "+---------------------------------------------------------------------------+\n",
       "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                            \u001b[0m|\n",
       "|------+-------+------------------------------------------------------------|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |   0   | tensor(4.7835, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  10   | tensor(4.5649, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  20   | tensor(2.7625, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  30   | tensor(3.4162, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  40   | tensor(3.1461, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  50   | tensor(2.9687, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  60   | tensor(2.9940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  70   | tensor(2.9289, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  80   | tensor(3.8940, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  0   |  90   | tensor(2.1735, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |   0   | tensor(2.4559, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  10   | tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  20   | tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  30   | tensor(2.1780, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  40   | tensor(2.9813, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  50   | tensor(2.7609, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  60   | tensor(2.2163, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  70   | tensor(2.4669, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  80   | tensor(1.9836, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  1   |  90   | tensor(1.7150, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |   0   | tensor(1.9767, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  10   | tensor(1.9896, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  20   | tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  30   | tensor(2.2766, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  40   | tensor(1.3339, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  50   | tensor(2.1953, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  60   | tensor(1.5729, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  70   | tensor(2.3212, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  80   | tensor(2.0933, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "|  2   |  90   | tensor(1.7745, device='cuda:0', grad_fn=<NllLossBackward0>)|\n",
       "+---------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:44:11] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#93\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">93</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:44:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                     \u001b]8;id=827660;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=185255;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#93\u001b\\\u001b[2m93\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                      \u001b[2m                                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:44:12] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#100\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:44:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m           \u001b]8;id=169976;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=622010;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#100\u001b\\\u001b[2m100\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                     \u001b[2m                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m10\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Completed \u001b[1;36m20\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12:44:31] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>              <a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">CreatorTemp/ipykernel_34632/3436021337.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#108\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12:44:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m              \u001b]8;id=167510;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py\u001b\\\u001b[2mCreatorTemp/ipykernel_34632/3436021337.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=239009;file://C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_34632\\3436021337.py#108\u001b\\\u001b[2m108\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                                     \u001b[2m                                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs\\model_files\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs\\model_files\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs\\predictions.csv\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs\\logs.txt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs\\logs.txt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T5Trainer(dataframe=df[:500], source_text=\"text\", target_text=\"headlines\", model_params=model_params, output_dir=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3f478e",
   "metadata": {},
   "source": [
    "#### Calculate BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6d6f6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TRG_LANGUAGE = 'en'\n",
    "\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TRG_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e2ac06c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentence:  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "Tokenization:  ['Saurav', 'Kant', ',', 'an', 'alumnus', 'of', 'upGrad', 'and', 'IIIT', '-', 'B', \"'s\", 'PG', 'Program', 'in', 'Machine', 'learning', 'and', 'Artificial', 'Intelligence', ',', 'was', 'a', 'Sr', 'Systems', 'Engineer', 'at', 'Infosys', 'with', 'almost', '5', 'years', 'of', 'work', 'experience', '.', 'The', 'program', 'and', 'upGrad', \"'s\", '360', '-', 'degree', 'career', 'support', 'helped', 'him', 'transition', 'to', 'a', 'Data', 'Scientist', 'at', 'Tech', 'Mahindra', 'with', '90', '%', 'salary', 'hike', '.', 'upGrad', \"'s\", 'Online', 'Power', 'Learning', 'has', 'powered', '3', 'lakh+', 'careers', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenize for example\n",
    "#example of tokenization of the english part\n",
    "print(\"English sentence: \", df['text'][0])\n",
    "print(\"Tokenization: \", token_transform[TRG_LANGUAGE](df['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "274e3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def calculate_bleu(iterator, model, device, max_len = 50):\n",
    "    \n",
    "    trgs = []\n",
    "    pred_trgs = []\n",
    "    \n",
    "    for src, trg in iterator:\n",
    "        \n",
    "#         pred_trg, _ = translate_sentence(src, model, device, max_len)\n",
    "        \n",
    "        #cut off <eos> token\n",
    "        pred_trg = token_transform[SRC_LANGUAGE](src.rstrip(\"\\n\"))\n",
    "        \n",
    "        #tokenize target sentence so it can be compared with pred_trgs\n",
    "        trg = token_transform[TRG_LANGUAGE](trg.rstrip(\"\\n\"))\n",
    "        \n",
    "        pred_trgs.append(pred_trg)\n",
    "        trgs.append([trg])\n",
    "        \n",
    "#         print(pred_trgs)\n",
    "    \n",
    "    return bleu_score(pred_trgs, trgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c9cfde",
   "metadata": {},
   "source": [
    "Test with 1 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "275b67ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['upGrad', 'learner', 'switches', 'to', 'career', 'in', 'ML', '&', 'Al', 'with', '90', '%', 'salary', 'hike']\n",
      "---\n",
      "['Saurav', 'Kant', ',', 'an', 'alumnus', 'of', 'upGrad', 'and', 'IIIT', '-', 'B', \"'s\", 'PG', 'Program', 'in', 'Machine', 'learning', 'and', 'Artificial', 'Intelligence', ',', 'was', 'a', 'Sr', 'Systems', 'Engineer', 'at', 'Infosys', 'with', 'almost', '5', 'years', 'of', 'work', 'experience', '.', 'The', 'program', 'and', 'upGrad', \"'s\", '360', '-', 'degree', 'career', 'support', 'helped', 'him', 'transition', 'to', 'a', 'Data', 'Scientist', 'at', 'Tech', 'Mahindra', 'with', '90', '%', 'salary', 'hike', '.', 'upGrad', \"'s\", 'Online', 'Power', 'Learning', 'has', 'powered', '3', 'lakh+', 'careers', '.']\n"
     ]
    }
   ],
   "source": [
    "test_head = df['headlines'][0]\n",
    "test_text = df['text'][0]\n",
    "\n",
    "test_h_token = token_transform[SRC_LANGUAGE](test_head.rstrip(\"\\n\"))\n",
    "test_t_token = token_transform[TRG_LANGUAGE](test_text.rstrip(\"\\n\"))\n",
    "\n",
    "print(test_h_token)\n",
    "print('---')\n",
    "print(test_t_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f5843854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunrise Lee gave doctor lap dance to persuade ...</td>\n",
       "      <td>Pharma exec gave doctor a lap dance to sell me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PM Modi says opposition talks only about Modi ...</td>\n",
       "      <td>I think the opposition even dreams about me: P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Indian Space Research Organisation unveils hum...</td>\n",
       "      <td>ISRO unveils Bengaluru centre for manned space...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rahul Gandhi replies to Goa CM's letter accusi...</td>\n",
       "      <td>CM Parrikar under pressure from PM after our G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>BMTC bus conductor returned bag of passenger w...</td>\n",
       "      <td>B'luru bus conductor returns bag containing 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>America's David Matheson divorced wife of 34 y...</td>\n",
       "      <td>US man who claimed to 'cure' gays with therapy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>Pierre-Hugues Herbert and Nicolas Mahut beat F...</td>\n",
       "      <td>Frenchmen Herbert, Mahut win Aus Open men's do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>Subramanian Swamy claims Priyanka suffers from...</td>\n",
       "      <td>Priyanka Gandhi has bipolar disorder, beats up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>ward boy arrested for filming woman changing c...</td>\n",
       "      <td>Pune ward boy films woman undressing for MRI s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                     Generated Text  \\\n",
       "0            0  Kunal Shah's credit card bill payment platform...   \n",
       "1            1  Sunrise Lee gave doctor lap dance to persuade ...   \n",
       "2            2  PM Modi says opposition talks only about Modi ...   \n",
       "3            3  Indian Space Research Organisation unveils hum...   \n",
       "4            4  Rahul Gandhi replies to Goa CM's letter accusi...   \n",
       "..         ...                                                ...   \n",
       "95          95  BMTC bus conductor returned bag of passenger w...   \n",
       "96          96  America's David Matheson divorced wife of 34 y...   \n",
       "97          97  Pierre-Hugues Herbert and Nicolas Mahut beat F...   \n",
       "98          98  Subramanian Swamy claims Priyanka suffers from...   \n",
       "99          99  ward boy arrested for filming woman changing c...   \n",
       "\n",
       "                                          Actual Text  \n",
       "0   Delhi techie wins free food from Swiggy for on...  \n",
       "1   Pharma exec gave doctor a lap dance to sell me...  \n",
       "2   I think the opposition even dreams about me: P...  \n",
       "3   ISRO unveils Bengaluru centre for manned space...  \n",
       "4   CM Parrikar under pressure from PM after our G...  \n",
       "..                                                ...  \n",
       "95  B'luru bus conductor returns bag containing 1...  \n",
       "96  US man who claimed to 'cure' gays with therapy...  \n",
       "97  Frenchmen Herbert, Mahut win Aus Open men's do...  \n",
       "98  Priyanka Gandhi has bipolar disorder, beats up...  \n",
       "99  Pune ward boy films woman undressing for MRI s...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c47b8ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Kunal Shah's credit card bill payment platform gives users a chance to win free food from Swiggy\",\n",
       " 'Delhi techie wins free food from Swiggy for one year on CRED')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('outputs/predictions.csv')\n",
    "\n",
    "test_iter = []\n",
    "\n",
    "for a in test_df.iterrows():\n",
    "    test_iter.append((a[1]['Generated Text'], a[1]['Actual Text']))\n",
    "    \n",
    "    \n",
    "test_iter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "acda47c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score | base model = 10.17\n"
     ]
    }
   ],
   "source": [
    "# test_iter = Multi30k(split=('test'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
    "bleu_score = calculate_bleu(test_iter, model, device)\n",
    "\n",
    "print(f'BLEU score | base model = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ad87c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('outputs/ablation_predictions.csv')\n",
    "test_df = test_df.drop([9])\n",
    "\n",
    "test_iter = []\n",
    "\n",
    "for a in test_df.iterrows():\n",
    "    test_iter.append((a[1]['Generated Text'], a[1]['Actual Text']))\n",
    "    \n",
    "    \n",
    "# test_df[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0ca2dfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score | ablation model = 10.17\n"
     ]
    }
   ],
   "source": [
    "# test_iter = Multi30k(split=('test'), language_pair=(SRC_LANGUAGE, TRG_LANGUAGE))\n",
    "bleu_score = calculate_bleu(test_iter, model, device)\n",
    "\n",
    "print(f'BLEU score | ablation model = {bleu_score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692963b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207117f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
