{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13f49b3c",
   "metadata": {},
   "source": [
    "# 4. Truncation without training on 1000 samples t5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219af75",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939b01c",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef95dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, tokenization_utils_base, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "device = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0aa9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/test_set.txt') as json_file:\n",
    "    test_set = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6659e9b",
   "metadata": {},
   "source": [
    "## 2. Scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b953373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(predictions, actuals, tokenizer):\n",
    "    \n",
    "    # <your code here>\n",
    "    metric = load_metric(\"rouge\")\n",
    "    result = metric.compute(predictions=predictions, references=actuals, use_stemmer=True)\n",
    "    \n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    rouge = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44abbe",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd42387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define model parameters specific to BART\n",
    "model_params = {\n",
    "    \"MODEL\": \"gniemiec/t5-small-finetuned-xsum\",\n",
    "    \"MAX_SOURCE_TEXT_LENGTH\": 512,  # max length of source text\n",
    "    \"MAX_TARGET_TEXT_LENGTH\": 36,  # max length of target text\n",
    "    \"SEED\": 42,  # set seed for reproducibility\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a144c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded gniemiec/t5-small-finetuned-xsum\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "np.random.seed(model_params[\"SEED\"])  # numpy random seed\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_params[\"MODEL\"])\n",
    "\n",
    "print(f\"Loaded {model_params['MODEL']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d33621",
   "metadata": {},
   "source": [
    "## 4. Test 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "534ddc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Police have recovered three firearms, ammunition and a five-figure sum of money.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # tokens = tokenizer(test_set['document'][1], return_tensors=\"pt\")\n",
    "    tokens = tokenizer.batch_encode_plus([test_set['document'][0]], \n",
    "                                         max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"], \n",
    "                                         truncation=True, \n",
    "                                         padding=\"max_length\", return_tensors=\"pt\").to(device)\n",
    "    # outputs = model.generate(tokens)\n",
    "    outputs = model.to(device).generate(\n",
    "                      input_ids = tokens.input_ids,\n",
    "                      attention_mask = tokens.attention_mask, \n",
    "                      max_length=150, \n",
    "                      num_beams=2,\n",
    "                      repetition_penalty=2.5, \n",
    "                      length_penalty=1.0, \n",
    "                      early_stopping=True\n",
    "                      )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428f0626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rouge1</th>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2</th>\n",
       "      <td>14.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeL</th>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rougeLsum</th>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_len</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "rouge1     33.3333\n",
       "rouge2     14.2857\n",
       "rougeL     20.0000\n",
       "rougeLsum  20.0000\n",
       "gen_len     1.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = compute_metrics([decoded], [test_set['summary'][0]], tokenizer)   \n",
    "rouge_df = pd.DataFrame.from_dict(rouge, orient='index')\n",
    "rouge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a471d52",
   "metadata": {},
   "source": [
    "## 5. Evaluate on 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7c97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix} | {iteration}/{total}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42def54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(device)\n",
    "predictions = []\n",
    "\n",
    "l = len(test_set['document'])\n",
    "printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "with torch.no_grad():\n",
    "    for idx, doc in enumerate(test_set['document']):\n",
    "        printProgressBar(idx + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "        tokens = tokenizer.batch_encode_plus([doc], \n",
    "                                             max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"], \n",
    "                                             truncation=True, \n",
    "                                             padding=\"max_length\", \n",
    "                                             return_tensors=\"pt\").to(device)\n",
    "       \n",
    "        outputs = model.generate(\n",
    "                      input_ids = tokens.input_ids,\n",
    "                      attention_mask = tokens.attention_mask, \n",
    "                      max_length=150, \n",
    "                      num_beams=2,\n",
    "                      repetition_penalty=2.5, \n",
    "                      length_penalty=1.0, \n",
    "                      early_stopping=True\n",
    "                      )\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22faa3",
   "metadata": {},
   "source": [
    "### 5.1 Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20339dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(predictions, actuals, output):\n",
    "    df = pd.DataFrame({'predictions': predictions, 'actuals': actuals})\n",
    "    df.to_csv(output)\n",
    "    print(\"PREDICTIONS RESULTS SAVED.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e64865",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(predictions, test_set['summary'], 'outputs/predictions_pretrained_t5xsum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c133c37",
   "metadata": {},
   "source": [
    "## 6. Create truncated tokens list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7011cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Trainer(output_dir, strategy=\"none\", no_tokens=70):\n",
    "    '''\n",
    "    source: array of documents\n",
    "    strategy:\n",
    "        - head: truncate head\n",
    "        - tail: truncate tail \n",
    "        - both: truncate head and tail\n",
    "        - middle: truncate middle words\n",
    "    words_no: number of tokens to remove\n",
    "    '''\n",
    "    print(f\"Strategy: Remove {strategy} tokens\")\n",
    "    l = len(test_set['document'])\n",
    "    \n",
    "    \n",
    "    torch.manual_seed(model_params[\"SEED\"])  # pytorch random seed\n",
    "    np.random.seed(model_params[\"SEED\"])  # numpy random seedtokenizer = AutoTokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "    \n",
    "    print(\"Loading model..\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_params[\"MODEL\"])\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_params[\"MODEL\"])\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, doc in enumerate(test_set['document']):\n",
    "            printProgressBar(idx + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            tokens = tokenizer.batch_encode_plus([doc], \n",
    "                                                 max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"], \n",
    "                                                 truncation=True, \n",
    "                                                 padding=\"max_length\", \n",
    "                                                 return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            source = tokens.input_ids[0]\n",
    "            attention = tokens.attention_mask[0]\n",
    "            \n",
    "            if strategy == \"middle\":\n",
    "                \n",
    "                left_remove_percent = .20\n",
    "                \n",
    "                no_real_tokens = sum(x != 0 for x in source)\n",
    "                left = int(left_remove_percent * no_real_tokens)\n",
    "                \n",
    "                # 3. Truncate left and right, concat both (input ids and attention mask)\n",
    "                left_selection_ids = source[:left]\n",
    "                right_selection_ids = source[left+no_tokens:len(source)]\n",
    "\n",
    "                left_attention_mask = attention[:left]\n",
    "                right_attention_mask = attention[left+no_tokens:len(source)]\n",
    "\n",
    "                new_ids = torch.concat([left_selection_ids, right_selection_ids], 0)        \n",
    "                new_masks = torch.concat([left_attention_mask,right_attention_mask], 0)\n",
    "\n",
    "                new_ids = new_ids.tolist()\n",
    "                new_masks = new_masks.tolist()\n",
    "\n",
    "                # 4. Create a new source text\n",
    "                new_encoding = {\n",
    "                    'input_ids': torch.IntTensor([new_ids]).to(dtype=torch.long),\n",
    "                    'attention_mask': torch.IntTensor([new_masks]).to(dtype=torch.long)\n",
    "                }\n",
    "                \n",
    "\n",
    "                # 5. Set new token encoding\n",
    "                new_tokens = tokenization_utils_base.BatchEncoding(new_encoding).to(device)\n",
    "                \n",
    "                \n",
    "            elif strategy == \"head\":\n",
    "                new_ids = source[no_tokens:].tolist()\n",
    "                new_masks = attention[no_tokens:].tolist()\n",
    "\n",
    "                # 4. Create a new source text\n",
    "                new_encoding = {\n",
    "                    'input_ids': torch.IntTensor([new_ids]).to(dtype=torch.long),\n",
    "                    'attention_mask': torch.IntTensor([new_masks]).to(dtype=torch.long)\n",
    "                }\n",
    "                \n",
    "\n",
    "                # 5. Set new token encoding\n",
    "                new_tokens = tokenization_utils_base.BatchEncoding(new_encoding).to(device)\n",
    "                \n",
    "            elif strategy == \"tail\":\n",
    "                no_real_tokens = sum(x != 0 for x in source)\n",
    "                zeros = source[no_real_tokens:]\n",
    "                \n",
    "                new_ids = torch.concat([source[:no_real_tokens-no_tokens],zeros], 0).tolist()\n",
    "                new_masks = torch.concat([attention[:no_real_tokens-no_tokens],zeros], 0).tolist()\n",
    "                \n",
    "                \n",
    "                new_encoding = {\n",
    "                    'input_ids': torch.IntTensor([new_ids]).to(dtype=torch.long),\n",
    "                    'attention_mask': torch.IntTensor([new_masks]).to(dtype=torch.long)\n",
    "                }\n",
    "                new_tokens = tokenization_utils_base.BatchEncoding(new_encoding).to(device)\n",
    "                \n",
    "            elif strategy == \"both\":\n",
    "                pass\n",
    "            else:\n",
    "                new_tokens = tokens\n",
    "            \n",
    "            outputs = model.generate(\n",
    "                          input_ids = new_tokens.input_ids,\n",
    "                          attention_mask = new_tokens.attention_mask, \n",
    "                          max_length=150, \n",
    "                          num_beams=2,\n",
    "                          repetition_penalty=2.5, \n",
    "                          length_penalty=1.0, \n",
    "                          early_stopping=True\n",
    "                          )\n",
    "            \n",
    "            decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predictions.append(decoded)\n",
    "            \n",
    "    save_results(predictions, test_set['summary'], os.path.join(output_dir,f'predictions_{strategy}_{no_tokens}.csv'))\n",
    "    \n",
    "    rouge = compute_metrics(predictions, test_set['summary'], tokenizer)\n",
    "    \n",
    "    rouge_df = pd.DataFrame.from_dict(rouge, orient='index')\n",
    "    rouge_df.to_csv(os.path.join(output_dir, f'rouge_score_{strategy}_{no_tokens}.csv'))\n",
    "    print(f\"SAVE ROUGE TO CSV FINISHED @ {os.path.join(output_dir, f'rouge_score_{strategy}_{no_tokens}.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3b5e3",
   "metadata": {},
   "source": [
    "## 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aac61102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #middle words\n",
    "# Trainer(output_dir='outputs_with_truncation/', strategy=\"middle\", no_tokens=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58d0d214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>20.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>3.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>14.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>14.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        0\n",
       "0     rouge1  20.2283\n",
       "1     rouge2   3.5699\n",
       "2     rougeL  14.8051\n",
       "3  rougeLsum  14.7833\n",
       "4    gen_len   1.0000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_df_middle = pd.read_csv('outputs_with_truncation/rouge_score_middle.csv')\n",
    "rouge_df_middle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdc781d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model..\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete | 1000/1000\n",
      "PREDICTIONS RESULTS SAVED.\n",
      "SAVE ROUGE TO CSV FINISHED @ outputs_with_truncation/rouge_score_none.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>22.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>4.4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>16.3347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>16.3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        0\n",
       "0     rouge1  22.2732\n",
       "1     rouge2   4.4585\n",
       "2     rougeL  16.3347\n",
       "3  rougeLsum  16.3285\n",
       "4    gen_len   1.0000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "Trainer(output_dir='outputs_with_truncation/', strategy=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91d01335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>22.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>4.4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>16.3347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>16.3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        0\n",
       "0     rouge1  22.2732\n",
       "1     rouge2   4.4585\n",
       "2     rougeL  16.3347\n",
       "3  rougeLsum  16.3285\n",
       "4    gen_len   1.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_df = pd.read_csv('outputs_with_truncation/rouge_score_none.csv')\n",
    "rouge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59eb547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: Remove head tokens\n",
      "Loading model..\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete | 1000/1000\n",
      "PREDICTIONS RESULTS SAVED.\n",
      "SAVE ROUGE TO CSV FINISHED @ outputs_with_truncation/rouge_score_head.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>19.0926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>3.5937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>14.0856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>14.0834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        0\n",
       "0     rouge1  19.0926\n",
       "1     rouge2   3.5937\n",
       "2     rougeL  14.0856\n",
       "3  rougeLsum  14.0834\n",
       "4    gen_len   1.0000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head words\n",
    "Trainer(output_dir='outputs_with_truncation/', strategy=\"head\", no_tokens=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88756085",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_df_head = pd.read_csv('outputs_with_truncation/rouge_score_head.csv')\n",
    "rouge_df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7430686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy: Remove tail tokens\n",
      "Loading model..\n",
      "Progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.0% Complete | 1000/1000\n",
      "PREDICTIONS RESULTS SAVED.\n",
      "SAVE ROUGE TO CSV FINISHED @ outputs_with_truncation/rouge_score_tail_70.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>19.4498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>3.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>13.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>13.7329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0        0\n",
       "0     rouge1  19.4498\n",
       "1     rouge2   3.0035\n",
       "2     rougeL  13.7329\n",
       "3  rougeLsum  13.7329\n",
       "4    gen_len   1.0000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tail words\n",
    "Trainer(output_dir='outputs_with_truncation/', strategy=\"tail\", no_tokens=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753d07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_df_tail = pd.read_csv('outputs_with_truncation/rouge_score_tail_70.csv')\n",
    "rouge_df_tail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bb926",
   "metadata": {},
   "source": [
    "## 8. RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41068834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>none</th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>middle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge1</td>\n",
       "      <td>22.2732</td>\n",
       "      <td>19.0926</td>\n",
       "      <td>19.4498</td>\n",
       "      <td>20.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2</td>\n",
       "      <td>4.4585</td>\n",
       "      <td>3.5937</td>\n",
       "      <td>3.0035</td>\n",
       "      <td>3.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rougeL</td>\n",
       "      <td>16.3347</td>\n",
       "      <td>14.0856</td>\n",
       "      <td>13.7329</td>\n",
       "      <td>14.8051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rougeLsum</td>\n",
       "      <td>16.3285</td>\n",
       "      <td>14.0834</td>\n",
       "      <td>13.7329</td>\n",
       "      <td>14.7833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gen_len</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0     none     head     tail   middle\n",
       "0     rouge1  22.2732  19.0926  19.4498  20.2283\n",
       "1     rouge2   4.4585   3.5937   3.0035   3.5699\n",
       "2     rougeL  16.3347  14.0856  13.7329  14.8051\n",
       "3  rougeLsum  16.3285  14.0834  13.7329  14.7833\n",
       "4    gen_len   1.0000   1.0000   1.0000   1.0000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = rouge_df.rename(columns={'0': 'none'})\n",
    "comparison_df['head'] =rouge_df_head['0']\n",
    "comparison_df['tail']= rouge_df_tail['0']\n",
    "comparison_df['middle'] = rouge_df_middle['0']\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07328a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
