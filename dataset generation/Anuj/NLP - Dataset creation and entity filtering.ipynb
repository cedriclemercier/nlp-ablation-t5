{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4164bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from tqdm import tqdm\n",
    "from flair.data import Sentence\n",
    "from flair.models import MultiTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c29860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ec21b",
   "metadata": {},
   "source": [
    "# Creation of baseline dataset for everyone (1000 samples <512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bd45b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ae8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a195760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dataset\n",
    "\n",
    "# testing_data = data['test'][0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23fedde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data['document'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c41dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data['summary'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef15c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d54fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flair.data import Sentence\n",
    "# from flair.models import MultiTagger\n",
    "\n",
    "# test_set = {'document':[], 'summary': []}\n",
    "\n",
    "\n",
    "# for count, document in enumerate(testing_data['document'], start=0):\n",
    "#     text = Sentence(document)\n",
    "#     if len(text.tokens) < 512:\n",
    "#         test_set['document'].append(document)\n",
    "#         test_set['summary'].append(testing_data['summary'][count])\n",
    "#         if len(test_set['document']) > 999:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a943c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "  \n",
    "# with open('convert.txt', 'w') as convert_file:\n",
    "#      convert_file.write(json.dumps(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1ee44",
   "metadata": {},
   "source": [
    "# Filter out POS and NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf92487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gniemiec/t5-small-finetuned-xsum\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gniemiec/t5-small-finetuned-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a10361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_set.txt') as json_file:\n",
    "    test_set = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50e345e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 48-year-old former Arsenal goalkeeper played for the Royals for four years.\\nHe was appointed youth academy director in 2000 and has been director of football since 2003.\\nA West Brom statement said: \"He played a key role in the Championship club twice winning promotion to the Premier League in 2006 and 2012.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['document'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4517a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'West Brom have appointed Nicky Hammond as technical director, ending his 20-year association with Reading.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['summary'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44402afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge/requirements.txt\n",
    "# !pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb7ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rouge_score import rouge_scorer\n",
    "\n",
    "# scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "# scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "#                       'The quick brown dog jumps on the log.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7272d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765),\n",
       " 'rougeL': Score(precision=0.625, recall=0.5555555555555556, fmeasure=0.5882352941176471)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b1e6e",
   "metadata": {},
   "source": [
    "## Run over 1000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9111c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 18:18:49,166 --------------------------------------------------------------------------------\n",
      "2022-04-13 18:18:49,168 The model key 'ner-fast' now maps to 'https://huggingface.co/flair/ner-english-fast' on the HuggingFace ModelHub\n",
      "2022-04-13 18:18:49,169  - The most current version of the model is automatically downloaded from there.\n",
      "2022-04-13 18:18:49,169  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner-fast/en-ner-fast-conll03-v0.4.pt)\n",
      "2022-04-13 18:18:49,170 --------------------------------------------------------------------------------\n",
      "2022-04-13 18:18:50,343 loading file C:\\Users\\anujg\\.flair\\models\\ner-english-fast\\4c58e7191ff952c030b82db25b3694b58800b0e722ff15427f527e1631ed6142.e13c7c4664ffe2bbfa8f1f5375bd0dced866b8c1dd7ff89a6d705518abf0a611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [47:15<00:00,  2.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from flair.models import MultiTagger\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load tagger for POS and NER \n",
    "tagger = MultiTagger.load(['ner-fast'])\n",
    "\n",
    "nouns_filtered = {'document': [], 'summary': test_set['summary']}\n",
    "\n",
    "for count, document in enumerate(tqdm(test_set['document'])):\n",
    "    sentence = Sentence(document)\n",
    "    tagger.predict(sentence)\n",
    "    \n",
    "    non_nouns = [token for token in sentence if token.get_tag('upos-fast').value not in ['NOUN','PROPN']]\n",
    "    \n",
    "#     for token in sentence:\n",
    "#         print(token.get_tag('ner-fast'))\n",
    "    \n",
    "    \n",
    "    filtered = []\n",
    "\n",
    "    for non_noun in non_nouns:\n",
    "#         print(non_noun)\n",
    "        filtered.append(non_noun.text)\n",
    "    \n",
    "    filtered_sentence = ' '.join(filtered)\n",
    "    nouns_filtered['document'].append(filtered_sentence)\n",
    "#     print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1107e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns_filtered['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8fea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns_filtered['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a93b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ORG_filtered.txt', 'w') as convert_file:\n",
    "     convert_file.write(json.dumps(nouns_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6645db",
   "metadata": {},
   "source": [
    "# Repeat for all POS and NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object_methods = [method_name for method_name in dir(token)\n",
    "#                   if callable(getattr(token, method_name))]\n",
    "# object_methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
